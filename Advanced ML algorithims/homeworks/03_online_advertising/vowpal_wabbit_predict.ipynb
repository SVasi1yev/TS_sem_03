{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_adv.txt\ttest.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_LINES: 29989752\n",
      "TRAIN_LINES: 14994876\n",
      "VALID_LINES: 14994876\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data/'\n",
    "FULL_LINES = 29989752\n",
    "TRAIN_LINES = int(FULL_LINES * 0.5)\n",
    "VALID_LINES = FULL_LINES - TRAIN_LINES\n",
    "print('FULL_LINES:', FULL_LINES)\n",
    "print('TRAIN_LINES:', TRAIN_LINES)\n",
    "print('VALID_LINES:', VALID_LINES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379278800;0;2733540231;3500392421;4454;15573;11;995;2;176;15;671;384,382,96,88,185,49,385,268,448,438,279,420,124,123,5,3,17,133,71,409,330,59,57,302,304,395,275,151,113,99,154,155,76,412,139,333,332,335,334,399;;;32;0;0;106\n",
      "timestamp --- 0 --- 1379278800\n",
      "label --- 1 --- 0\n",
      "C1 --- 2 --- 2733540231\n",
      "C2 --- 3 --- 3500392421\n",
      "C3 --- 4 --- 4454\n",
      "C4 --- 5 --- 15573\n",
      "C5 --- 6 --- 11\n",
      "C6 --- 7 --- 995\n",
      "C7 --- 8 --- 2\n",
      "C8 --- 9 --- 176\n",
      "C9 --- 10 --- 15\n",
      "C10 --- 11 --- 671\n",
      "CG1 --- 12 --- 384,382,96,88,185,49,385,268,448,438,279,420,124,123,5,3,17,133,71,409,330,59,57,302,304,395,275,151,113,99,154,155,76,412,139,333,332,335,334,399\n",
      "CG2 --- 13 --- \n",
      "CG3 --- 14 --- \n",
      "l1 --- 15 --- 32\n",
      "l2 --- 16 --- 0\n",
      "C11 --- 17 --- 0\n",
      "C12 --- 18 --- 106\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_DIR + 'train.csv') as f:\n",
    "    fea_names = f.readline()[:-1].split(';')\n",
    "    line = f.readline()[:-1]\n",
    "    print(line)\n",
    "    features = line.split(';')\n",
    "    for i in range(len(fea_names)):\n",
    "        print(f'{fea_names[i]} --- {i} --- {features[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vm_from_csv(csv, vw, labels_=False, test=False):\n",
    "    global labels\n",
    "    if labels_:\n",
    "        labels = []\n",
    "    with open(DATA_DIR + csv) as f, open(vw, 'w') as out_f:\n",
    "        f.readline()\n",
    "        for line in tqdm(f, total=FULL_LINES):\n",
    "            features = line[:-1].split(';')\n",
    "            if test:\n",
    "                label=-1\n",
    "            else:\n",
    "                label = int(features[1]) * 2 - 1\n",
    "            if labels_:\n",
    "                labels.append(int(features[1]))\n",
    "            res = f'{label} '\n",
    "\n",
    "            res += '|i '\n",
    "            res += f'l1:{features[15]} l2:{features[16]} '\n",
    "    #         res += '|j '\n",
    "    #         res += f'l1_{features[15]} l2_{features[16]} '\n",
    "\n",
    "            res += '|c '\n",
    "            for i in range(2, 12):\n",
    "                res += f'C{i-1}_{features[i]} '\n",
    "            res += f'C11_{features[17]} '\n",
    "            res += f'C12_{features[18]} '\n",
    "\n",
    "            res += '|l '\n",
    "            if features[12] != '':\n",
    "                for idx, fea in enumerate(features[12].split(',')):\n",
    "                    res += f'CG1_{0}_{fea} '\n",
    "\n",
    "            res += '|m '\n",
    "            if features[13] != '':\n",
    "                for idx, fea in enumerate(features[13].split(',')):\n",
    "                    res += f'CG2_{0}_{fea} '\n",
    "\n",
    "            res += '|n '\n",
    "            if features[14] != '':\n",
    "                for idx, fea in enumerate(features[14].split(',')):\n",
    "                    res += f'CG3_{0}_{fea} '\n",
    "\n",
    "            out_f.write(res + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29989752/29989752 [08:50<00:00, 56535.95it/s]\n"
     ]
    }
   ],
   "source": [
    "make_vm_from_csv('train.csv', 'full.vw', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('full.vw', 'r') as full, open('train.vw', 'w') as train, open('valid.vw', 'w') as valid:\n",
    "#     c = 0\n",
    "#     for line in tqdm(full, total=FULL_LINES):\n",
    "#         c += 1\n",
    "#         if c < TRAIN_LINES:\n",
    "#             train.write(line)\n",
    "#         else:\n",
    "#             valid.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !vw train.vw -f valid_model.vw --loss_function=logistic --link=logistic --passes 1 -c --cubic ccc -q ll -q mm -q nn --adaptive --normalized --l1 0.00000001 --l2 0.0000001 -b 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !vw -d valid.vw -t -i valid_model.vw --loss_function=logistic --link=logistic -p valid_pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(labels))\n",
    "# valid_labels = labels[TRAIN_LINES - 1:]\n",
    "# valid_pred = []\n",
    "# with open('valid_pred.txt', 'r') as f:\n",
    "#     count = 0\n",
    "#     for line in f:\n",
    "#         valid_pred.append(float(line[:-1]))\n",
    "#         count += 1\n",
    "#     print(len(valid_labels))\n",
    "#     print(len(valid_pred))\n",
    "# valid_labels_np = np.array(valid_labels)\n",
    "# valid_pred_np = np.array(valid_pred)\n",
    "# print(valid_labels_np.shape)\n",
    "# print(valid_pred_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "# print(log_loss(valid_labels_np, valid_pred_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.016967645176882876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: ll mm nn \n",
      "creating cubic features for triples: ccc \n",
      "using l1 regularization = 1e-08\n",
      "using l2 regularization = 1e-07\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 20\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = full.vw.cache\n",
      "Reading datafile = full.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000     1238\n",
      "0.354293 0.015439            2            2.0  -1.0000   0.0153      873\n",
      "0.187282 0.020270            4            4.0  -1.0000   0.0017     1513\n",
      "0.099674 0.012067            8            8.0  -1.0000   0.0000     3546\n",
      "0.050758 0.001842           16           16.0  -1.0000   0.0000      677\n",
      "0.026572 0.002386           32           32.0  -1.0000   0.0000      980\n",
      "0.020433 0.014294           64           64.0  -1.0000   0.0000     1120\n",
      "0.010804 0.001176          128          128.0  -1.0000   0.0000     2935\n",
      "0.007104 0.003403          256          256.0  -1.0000   0.0000     3305\n",
      "0.042153 0.077202          512          512.0  -1.0000   0.0000      782\n",
      "0.045398 0.048643         1024         1024.0  -1.0000   0.0000     1557\n",
      "0.041648 0.037897         2048         2048.0  -1.0000   0.0000      607\n",
      "0.059317 0.076986         4096         4096.0  -1.0000   0.0000     1581\n",
      "0.058619 0.057921         8192         8192.0  -1.0000   0.0000     1809\n",
      "0.061959 0.065299        16384        16384.0  -1.0000   0.0000      783\n",
      "0.052099 0.042239        32768        32768.0  -1.0000   0.0000     2522\n",
      "0.048233 0.044366        65536        65536.0  -1.0000   0.0000      787\n",
      "0.042694 0.037154       131072       131072.0  -1.0000   0.0000      530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1795632/29989752 [01:00<14:52, 31603.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044859 0.047025       262144       262144.0  -1.0000   0.0000     1602\n",
      "0.041378 0.037896       524288       524288.0  -1.0000   0.0001      814\n",
      "0.037000 0.032622      1048576      1048576.0  -1.0000   0.0383     1198\n",
      "0.030592 0.024185      2097152      2097152.0  -1.0000   0.0004      783\n",
      "0.024073 0.017554      4194304      4194304.0  -1.0000   0.0029     1080\n",
      "0.021247 0.018420      8388608      8388608.0  -1.0000   0.0001     1280\n",
      "0.018458 0.015670     16777216     16777216.0  -1.0000   0.0004     1009\n",
      "0.016759 0.016759     33554432     33554432.0  -1.0000   0.0003     2267 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 26990777\n",
      "passes used = 2\n",
      "weighted example sum = 53981554.000000\n",
      "weighted label sum = -53706702.000000\n",
      "average loss = 0.015166 h\n",
      "best constant = -5.970778\n",
      "best constant's loss = 0.017749\n",
      "total feature number = 73598626406\n"
     ]
    }
   ],
   "source": [
    "!vw full.vw -f model.vw --loss_function=logistic --link=logistic --passes 2 -c --cubic ccc -q ll -q mm -q nn --adaptive --normalized --l1 0.00000001 --l2 0.0000001 -b 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_vm_from_csv('test.csv', 'test.vw', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: ll mm nn \n",
      "creating cubic features for triples: ccc \n",
      "only testing\n",
      "predictions = pred.txt\n",
      "ignoring duplicate option: '--link=logistic'\n",
      "Num weight bits = 20\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.002456 0.002456            1            1.0  -1.0000   0.0025     1117\n",
      "0.001449 0.000442            2            2.0  -1.0000   0.0004     2201\n",
      "0.004047 0.006645            4            4.0  -1.0000   0.0124      732\n",
      "0.005147 0.006248            8            8.0  -1.0000   0.0005      755\n",
      "0.003345 0.001543           16           16.0  -1.0000   0.0003     2201\n",
      "0.002921 0.002496           32           32.0  -1.0000   0.0065      729\n",
      "0.003204 0.003487           64           64.0  -1.0000   0.0008     2030\n",
      "0.003494 0.003785          128          128.0  -1.0000   0.0008     1157\n",
      "0.003101 0.002707          256          256.0  -1.0000   0.0003      550\n",
      "0.003105 0.003109          512          512.0  -1.0000   0.0009     2937\n",
      "0.002733 0.002362         1024         1024.0  -1.0000   0.0008      629\n",
      "0.002421 0.002108         2048         2048.0  -1.0000   0.0004     1043\n",
      "0.002450 0.002478         4096         4096.0  -1.0000   0.0033      727\n",
      "0.002353 0.002257         8192         8192.0  -1.0000   0.0008     1652\n",
      "0.002303 0.002252        16384        16384.0  -1.0000   0.0016     1161\n",
      "0.002415 0.002527        32768        32768.0  -1.0000   0.0007      566\n",
      "0.002471 0.002528        65536        65536.0  -1.0000   0.0080     1605\n",
      "0.002594 0.002717       131072       131072.0  -1.0000   0.0111     1282\n",
      "0.002776 0.002958       262144       262144.0  -1.0000   0.0008      940\n",
      "0.002933 0.003090       524288       524288.0  -1.0000   0.0114      702\n",
      "0.003269 0.003605      1048576      1048576.0  -1.0000   0.0004     1080\n",
      "0.003309 0.003349      2097152      2097152.0  -1.0000   0.0006     1238\n",
      "0.003166 0.003022      4194304      4194304.0  -1.0000   0.0001     2088\n",
      "0.003032 0.002897      8388608      8388608.0  -1.0000   0.0022     1509\n",
      "0.002897 0.002763     16777216     16777216.0  -1.0000   0.0007     1808\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 20317220\n",
      "passes used = 1\n",
      "weighted example sum = 20317220.000000\n",
      "weighted label sum = -20317220.000000\n",
      "average loss = 0.002959\n",
      "best constant = -1.000000\n",
      "best constant's loss = 0.313262\n",
      "total feature number = 27733651176\n"
     ]
    }
   ],
   "source": [
    "!vw -d test.vw -t -i model.vw --loss_function=logistic --link=logistic -p pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pred.txt', 'r') as in_f, open('sub0.txt', 'w') as out_f:\n",
    "    out_f.write(\"Id,Click\\n\")\n",
    "    for idx, line in enumerate(tqdm(in_f)):\n",
    "        out_f.write(\"{},{}\".format(idx+1, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
